{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from __init__ import *\n",
    "\n",
    "__ORIG_WD__ = os.getcwd()\n",
    "os.chdir(f\"{__ORIG_WD__}/../data_collectors\")\n",
    "\n",
    "from covid19_genome import Covid19Genome\n",
    "\n",
    "os.chdir(__ORIG_WD__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = Covid19Genome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineages = dc.getLocalLineages()\n",
    "\n",
    "mappings = []\n",
    "accessions = for lineage in lineages:\n",
    "    for accession in dc.getLocalAccessionsPaths(lineage):\n",
    "        mappings.append((accession, lineage))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def compute_coverage(n, indexes, read_lengths):\n",
    "    # Create a range tensor [0, 1, 2, ... n-1]\n",
    "    range_tensor = tf.range(n, dtype=tf.int32)\n",
    "\n",
    "    # Expand dims for broadcasting\n",
    "    expanded_range = tf.expand_dims(range_tensor, 0)\n",
    "    expanded_indexes = tf.expand_dims(indexes, 1)\n",
    "    expanded_lengths = tf.expand_dims(read_lengths, 1)\n",
    "\n",
    "    # Create a binary mask for each read\n",
    "    # Each row in the mask represents where the read starts and its length\n",
    "    print((expanded_range >= expanded_indexes).shape)\n",
    "    mask = tf.logical_and(expanded_range >= expanded_indexes,\n",
    "                          expanded_range < expanded_indexes + expanded_lengths)\n",
    "\n",
    "    # Convert the boolean mask to integers and sum across rows\n",
    "    coverage = tf.reduce_sum(tf.cast(mask, tf.int32), axis=0)\n",
    "    \n",
    "    return coverage\n",
    "\n",
    "# Example\n",
    "n = 10\n",
    "indexes = tf.constant([1, 2, 5], dtype=tf.int32)\n",
    "read_lengths = tf.constant([3, 20, 2], dtype=tf.int32)\n",
    "\n",
    "coverage_per_base = compute_coverage(n, indexes, read_lengths)\n",
    "print(coverage_per_base.numpy())  # Expected: [0, 1, 1, 1, 0, 1, 1, 0, 0, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.tensor_scatter_nd_add(\n",
    "    tf.zeros([3], tf.constant([0], [0]), tf.constant([1,1]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def propagate_values(vector):\n",
    "    # Find where the vector is not zero\n",
    "    non_zeros = tf.cast(tf.not_equal(vector, 0), dtype=tf.int32)\n",
    "\n",
    "    # Get the cumulative sum of non-zero locations\n",
    "    cum_sum = tf.cumsum(non_zeros)\n",
    "\n",
    "    # Create a mask to gather elements\n",
    "    mask = cum_sum * non_zeros\n",
    "\n",
    "    # Use tf.gather to replace zeros with latest non-zero value\n",
    "    propagated_values = tf.gather(tf.boolean_mask(vector, mask), cum_sum - 1)\n",
    "\n",
    "    return propagated_values\n",
    "\n",
    "# Example\n",
    "vec = tf.constant([0, 0, 0, -1, 0, 0, 0, -2, 0, 0, 0], dtype=tf.int32)\n",
    "result = propagate_values(vec)\n",
    "print(result.numpy())  # Expected: [0,0,0,3,3,3,3,3,8,8,8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant([1,2,3,4,5])\n",
    "tf.diff(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_partition(balls, bins):\n",
    "    \"\"\"\n",
    "    1 represents a ball\n",
    "    0 represents a partition\n",
    "    \"\"\"\n",
    "    # randomize the ones indexes\n",
    "    balls_indexes = tf.random.shuffle(tf.range(balls+bins-1))[:balls]\n",
    "    balls_and_partitions = tf.concat([\n",
    "        tf.scatter_nd(\n",
    "            indices=tf.expand_dims(balls_indexes, 1),\n",
    "            updates=tf.ones(balls, dtype=tf.dtypes.int32),\n",
    "            shape=[bins+balls-1]\n",
    "        ), \n",
    "        [0]\n",
    "    ], axis=-1)\n",
    "    \n",
    "    # cumsum of balls and partitions\n",
    "    cumsum = tf.cumsum(balls_and_partitions)\n",
    "\n",
    "    summed_balls_per_partition = tf.boolean_mask(cumsum, balls_and_partitions == 0)\n",
    "\n",
    "    prev_balls_per_partition = tf.concat([[0], summed_balls_per_partition[:-1]], axis = -1)\n",
    "\n",
    "    return summed_balls_per_partition - prev_balls_per_partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_coverage_per_base(genome_length, read_length, coverage):\n",
    "    num_reads = tf.cast(tf.math.ceil(coverage * genome_length / read_length), tf.int32)\n",
    "    read_starts_per_base = tf.concat(\n",
    "        [\n",
    "            random_partition(\n",
    "                balls = num_reads,\n",
    "                bins = genome_length - read_length + 1,\n",
    "            ),\n",
    "            tf.zeros(read_length, dtype=tf.int32)\n",
    "        ],\n",
    "        axis=-1\n",
    "    )\n",
    "    tf.print(read_starts_per_base)\n",
    "    read_ends_per_base = -1*tf.roll(read_starts_per_base, read_length, axis=0)\n",
    "    tf.print(read_ends_per_base)\n",
    "    coverage_per_base = tf.cumsum(read_starts_per_base + read_ends_per_base)\n",
    "    return coverage_per_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_compute_coverage_per_base(5, 2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 256, 128, 32)\n",
      "(32, 256, 64, 32)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "# The inputs are 128-length vectors with 10 timesteps, and the\n",
    "# batch size is 4.\n",
    "\n",
    "conv = tf.keras.layers.Conv1D(32, 3, activation='relu', padding=\"same\")\n",
    "\n",
    "input_shape = (32, 256, 128, 4)\n",
    "x = tf.random.normal(input_shape)\n",
    "y = (x)\n",
    "print(y.shape)\n",
    "y = tf.nn.max_pool(\n",
    "    y,\n",
    "    ksize=[1, 1, 2, 1],  # Pooling size: No pooling on batch1, batch2, and the last dimension. Pool every 2 elements in the third dimension.\n",
    "    strides=[1, 1, 2, 1],  # Stride: Move by 2 elements in the third dimension.\n",
    "    padding='VALID'\n",
    ")\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as first layer in a Sequential model\n",
    "\n",
    "reshape = tf.keras.layers.Reshape((None, 3, 4))\n",
    "# model.output_shape == (None, 3, 4), `None` is the batch size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49mnormal((\u001b[39mNone\u001b[39;49;00m,\u001b[39m10\u001b[39;49m,\u001b[39m3\u001b[39;49m,\u001b[39m4\u001b[39;49m))\n\u001b[1;32m      2\u001b[0m \u001b[39m# print(x)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/covit/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/covit/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:98\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[1;32m     97\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 98\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[0;31mValueError\u001b[0m: Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor."
     ]
    }
   ],
   "source": [
    "x = tf.random.normal((None,10,3,4))\n",
    "# print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "covit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
